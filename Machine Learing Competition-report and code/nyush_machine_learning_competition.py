# -*- coding: utf-8 -*-
"""NYUSH Machine Learning Competition

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g-IXxfL2j3WM8YdxGv2X56PQ4aRLHoUr

# Competition Introduction:
The Pokémon Fusion Image Competition focused on visual representation learning using convolutional autoencoders. Participants trained on about 18,000 Pokémon fusion images to learn compact latent features. Models were evaluated on image reconstruction, type classification across 170 categories via linear probing, and image generation. The final score combined reconstruction and classification accuracy, rewarding models that balanced compression efficiency with meaningful feature learning under size and runtime limits.

The finalized model architecture and pretrained weights, excluding the training procedure, were submitted to the competition server for evaluation on the hidden test set.
The reconstruction plot here is only for format reference, as the actual test evaluation output is more abstract and less visually interpretable.
"""

from google.colab import drive
import os

drive.mount('/content/drive')

# Mount to Google Drive & Switch to the dataset directory

os.chdir("/content/drive/MyDrive/Machine Learning project")
os.listdir()

import torch
import random
import numpy as np

# Set a fixed random seed for reproducibility
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed(SEED)
    torch.cuda.manual_seed_all(SEED)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image

class CustomDataset(Dataset):
    def __init__(self, npz_path):
        npz_data = np.load(npz_path)
        self.images = npz_data["images"] # (N, 3, 128, 128) in np.uint8
        self.labels = npz_data["labels"] # (N,) in np.int64
        assert self.images.shape[0] == self.labels.shape[0]
        print(f"{npz_path}: images shape {self.images.shape}, "
              f"labels shape {self.labels.shape}")

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        image = torch.tensor(self.images[idx]) / 255 # convert to [0, 1] range
        label = torch.tensor(self.labels[idx])
        return image, label

train_dataset = CustomDataset("train (1).npz")
train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=8, pin_memory=True,prefetch_factor = 4,)



# sample data batch
images, labels = next(iter(train_loader))
print(f"images shape: {images.shape}")
print(f"labels shape: {labels.shape}")

import matplotlib.pyplot as plt

# load label text
with open('label2type.txt', 'r') as f:
    label2type = eval(f.read())

# plot samples
fig, axes = plt.subplots(1, 4, figsize=(12, 4))
for i, ax in enumerate(axes):
    label = labels[i].item()
    # (C, H, W) to (H, W, C) for plotting
    ax.imshow(images[i].numpy().transpose(1, 2, 0))
    ax.axis('off')
    ax.set_title(f"{label}: {label2type[label]}")
plt.tight_layout()
plt.show()

import torch
import torch.nn as nn
import torch.nn.functional as F
from tqdm import tqdm


class ResBlock(nn.Module):
    def __init__(self, channels):
        super().__init__()
        self.conv_block = nn.Sequential(
            nn.Conv2d(channels, channels, kernel_size = 3, stride = 1,padding=1),
            nn.GroupNorm(min(8, channels), channels),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(channels, channels, kernel_size = 3, stride = 1,padding=1),
            nn.GroupNorm(min(8, channels), channels),
        )
        self.act = nn.LeakyReLU(0.2, inplace=True)

    def forward(self, x):
        return self.act(x + self.conv_block(x))

class ConvAE(nn.Module):
    def __init__(self, input_channels=3, latent_channels=8, num_classes=170):
        super().__init__()

        # --- Encoder ---
        self.encoder = nn.Sequential(
            nn.Conv2d(input_channels, 64, kernel_size=3, stride=2, padding=1),
            nn.GroupNorm(8, 64),
            nn.LeakyReLU(0.2, inplace=True),

            # ResBlock(64),

            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),
            nn.GroupNorm(8, 128),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
            nn.GroupNorm(8, 256),
            nn.LeakyReLU(0.2, inplace=True),

            # Encoder refinement
            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),
            nn.GroupNorm(8, 256),
            nn.LeakyReLU(0.2, inplace=True),
            ResBlock(256),
        )

        # --- Bottleneck linear mapping ---
        self.quant_conv = nn.Conv2d(256, latent_channels, kernel_size=1)

        # --- Decoder prep ---
        self.post_quant_conv = nn.Conv2d(latent_channels, 256, kernel_size=1)

        # --- Decoder ---
        self.decoder = nn.Sequential(

            nn.ConvTranspose2d(256, 256, kernel_size=3, stride=1, padding=1),
            nn.GroupNorm(8, 256),
            nn.LeakyReLU(0.1, inplace=True),
            ResBlock(256),

            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=1, padding=1),
            nn.GroupNorm(8, 128),
            nn.LeakyReLU(0.1, inplace=True),
            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.GroupNorm(8, 64),
            nn.LeakyReLU(0.2, inplace=True),
            #ResBlock(64),
            nn.ConvTranspose2d(64, input_channels, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.Sigmoid()
        )

        # --- Classification head ---
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(latent_channels, num_classes)
        )

    def encode(self, x):
        return self.quant_conv(self.encoder(x))

    def classify(self, z):
        return self.classifier(z)

    def decode(self, z):
        return self.decoder(self.post_quant_conv(z))
#
    def forward(self, x):
        z = self.encode(x)
        x_recon = self.decode(z)
        logits = self.classify(z)
        return x_recon, z, logits

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from tqdm import tqdm
from torch.optim.lr_scheduler import CosineAnnealingLR
from torch.utils.data import random_split, DataLoader
from torch.amp import autocast, GradScaler

import torch
import torch.nn.functional as F
from tqdm import tqdm

def loss_fn(x, x_recon, logits, labels):
    recon = F.mse_loss(x_recon, x, reduction='mean')
    ce    = F.cross_entropy(logits, labels)
    return torch.log(recon) + torch.log(ce), recon, ce

# —— train ——
def train_convae(model, train_loader, optimizer, scheduler, device, num_epochs=600):
    model.to(device)
    scaler = GradScaler()
    for epoch in range(1, num_epochs+1):
        model.train()
        sum_recon = sum_ce = sum_corr = sum_samples = 0
        loop = tqdm(train_loader, desc=f"Epoch {epoch}/{num_epochs}")
        for x, y in loop:
            x, y = x.to(device), y.to(device)
            optimizer.zero_grad()
            with autocast(device_type='cuda'):
                x_recon, z, logits = model(x)
                loss, recon, ce = loss_fn(x, x_recon, logits, y)
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            b = x.size(0)
            sum_recon   += recon.item() * b
            sum_ce      += ce.item()    * b
            sum_corr    += (logits.argmax(1) == y).sum().item()
            sum_samples += b

            lr = optimizer.param_groups[0]['lr']
            loop.set_postfix(
                loss=f"{loss.item():.6f}",
                mse=f"{recon.item():.6f}",
                ce=f"{ce.item():.6f}",
                lr=f"{lr:.6f}"
            )

        train_recon = sum_recon / sum_samples
        train_acc   = sum_corr  / sum_samples
        score       = train_recon / train_acc
        scheduler.step()
        lr = optimizer.param_groups[0]['lr']
        print(f"Epoch {epoch}: recon={train_recon:.6f}, acc={train_acc:.6f}, score={score:.6f}, lr={lr:.1e}")

    torch.save(model.state_dict(), 'final_weights.pt')




device = torch.device("cuda")
model = ConvAE(input_channels=3, latent_channels=8, num_classes=170).to(device)
optimizer = optim.AdamW(model.parameters(), lr=1e-3)

scheduler = CosineAnnealingLR(optimizer, T_max=200,eta_min=1e-5)
train_convae(model, train_loader, optimizer, scheduler, device, num_epochs=200)

# ----- Visualization -----
def plot_reconstructions(model, dataloader, device, num_images=8):
    model.eval()
    with torch.no_grad():
        x = next(iter(dataloader))[0].to(device)
        x_recon, z, logits = model(x)
        x = x.cpu().numpy()
        x_recon = x_recon.cpu().numpy()
        print(f"Latent bottleneck dimension: {z.flatten(start_dim=1).shape[1]}")

        plt.figure(figsize=(16, 4))
        for i in range(num_images):
            # Original
            plt.subplot(2, num_images, i+1)
            plt.imshow(x[i].transpose(1, 2, 0))  # (C, H, W) -> (H, W, C)
            plt.axis('off')

            # Reconstruction
            plt.subplot(2, num_images, i+1+num_images)
            plt.imshow(x_recon[i].transpose(1, 2, 0))
            plt.axis('off')
        plt.show()

plot_reconstructions(model, train_loader, device, num_images=8)

# Submission

# 1) Save model weights
torch.save(model.state_dict(), "checkpoint.pt")

# 2) Prepare the 'Model' class for submission
with open("model.py", "r") as f:
    print(f.read())

# 3) Submit the model code & weights online

# Metric 1: Recon MSE on test set (on value range [0, 1])
# Metric 2: Classification accuracy (linear probing with test set latents, 170 classes)
# Final Score: recon_mse / probing_accuracy (the lower the better)